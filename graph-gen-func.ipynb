{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import csv\n",
    "from numpy import genfromtxt\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "from glob import glob\n",
    "from pylab import *\n",
    "from matplotlib.pyplot import imread\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader, InMemoryDataset, Data, download_url, extract_zip\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_M(height_pixels, width_pixels):\n",
    "    fov_x = pi/3.0\n",
    "    fov_y = 2.0 * arctan(height_pixels * tan(fov_x/2.0) / width_pixels)\n",
    "    near  = 1.0\n",
    "    far   = 1000.0\n",
    "\n",
    "    f_h    = tan(fov_y/2.0)*near\n",
    "    f_w    = f_h*width_pixels/height_pixels\n",
    "    left   = -f_w\n",
    "    right  = f_w\n",
    "    bottom = -f_h\n",
    "    top    = f_h\n",
    "\n",
    "    M_proj      = matrix(zeros((4,4)))\n",
    "    M_proj[0,0] = (2.0*near)/(right - left)\n",
    "    M_proj[1,1] = (2.0*near)/(top - bottom)\n",
    "    M_proj[0,2] = (right + left)/(right - left)\n",
    "    M_proj[1,2] = (top + bottom)/(top - bottom)\n",
    "    M_proj[2,2] = -(far + near)/(far - near)\n",
    "    M_proj[3,2] = -1.0\n",
    "    M_proj[2,3] = -(2.0*far*near)/(far - near)\n",
    "    \n",
    "    return M_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world2screen_proj(p_world, camera_pos, camera_rot, height_pixels, width_pixels):\n",
    "    R_cam2world = matrix(camera_rot)\n",
    "    t_cam2world = matrix(camera_pos).T\n",
    "    R_world2cam = R_cam2world.T\n",
    "    t_world2cam = -R_world2cam*t_cam2world\n",
    "\n",
    "    M = construct_M(height_pixels, width_pixels)\n",
    "\n",
    "    p_cam      = t_world2cam + R_world2cam*p_world\n",
    "    p_cam_     = matrix(r_[ p_cam.A1, 1 ]).T\n",
    "    p_clip     = M * p_cam_\n",
    "    p_ndc      = p_clip/p_clip[3]\n",
    "    p_ndc_     = p_ndc.A1\n",
    "    p_screen_x = 0.5*(p_ndc_[0]+1)*(width_pixels-1)\n",
    "    p_screen_y = (1 - 0.5*(p_ndc_[1]+1))*(height_pixels-1)\n",
    "    p_screen_z = (p_ndc_[2]+1)/2.0\n",
    "    p_screen   = matrix([p_screen_x, p_screen_y, p_screen_z]).T\n",
    "    \n",
    "    return p_screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(mesh_objects_sii, mesh_objects_si, metadata_objects, nyu_labels, bb_pos):\n",
    "    bb_labels = []\n",
    "    bb_error = []\n",
    "    n_bb = bb_pos.shape[0] - 1\n",
    "    # nyu_id = np.zeros(n_bb)\n",
    "\n",
    "    for i in range(n_bb):\n",
    "        lowlvl_instances_in_current_bb = np.where(mesh_objects_sii == i+1)[0]\n",
    "        if lowlvl_instances_in_current_bb.size > 0:\n",
    "            nyu_id = mesh_objects_si[lowlvl_instances_in_current_bb[0]]\n",
    "            # bb_labels.append(nyu_labels[int(nyu_id[i])][1])\n",
    "            bb_labels.append(nyu_id)\n",
    "        else:\n",
    "           bb_error.append(i+1)\n",
    "           bb_labels.append(np.array([-1], dtype=int64)) # TODO: consider another solution to this problem (eg. remove BB that are 'invalid')\n",
    "    \n",
    "    return bb_labels, bb_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(threshold, a2m, bb_pos, bb_error):\n",
    "    n_bb = bb_pos.shape[0] - 1\n",
    "    bb_pos_m = bb_pos*a2m\n",
    "\n",
    "    distances = np.zeros((n_bb, n_bb))\n",
    "    distances[:, :] = np.nan\n",
    "\n",
    "    for i in range(n_bb):\n",
    "        for j in range(n_bb):\n",
    "            if i+1 not in bb_error and j+1 not in bb_error:\n",
    "                distances[i, j] = distance.euclidean(bb_pos_m[i+1, :], bb_pos_m[j+1, :])\n",
    "\n",
    "    distance_mask = (distances <= threshold)*int(1) # True for objects that are within [threshold] m of other objects\n",
    "    np.fill_diagonal(distance_mask, 0)\n",
    "    \n",
    "    return distance_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_adjacency_matrix(n_bb, bb_in_sample, distance_mask):    \n",
    "    # Array of BB to ignore in the adjacency matrix (not present in the graph)\n",
    "    temp = arange(1, n_bb+1) # goes from 1 to 55\n",
    "    bb_not_in_sample = np.delete(temp, bb_in_sample - np.ones(len(bb_in_sample), dtype=int))\n",
    "    index = bb_not_in_sample - np.ones(len(bb_not_in_sample), dtype=int)\n",
    "    \n",
    "    adjacency_matrix = copy(distance_mask)\n",
    "    adjacency_matrix[index,:] = np.zeros((len(bb_not_in_sample), n_bb))\n",
    "    adjacency_matrix[:, index] = np.zeros((n_bb, len(bb_not_in_sample)))\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene(n_bb, bb_pos, bb_in_sample, camera_pos, camera_rot, height_pixels, width_pixels, adjacency_matrix, bb_labels, tonemap):\n",
    "\n",
    "    # Attribute label to each graph node from the constructed labels for the scene\n",
    "    temp = arange(1, n_bb+1)\n",
    "    bb_not_in_sample = np.delete(temp, bb_in_sample - np.ones(len(bb_in_sample), dtype=int))\n",
    "    bb_in_sample_nodes = np.delete(temp, bb_not_in_sample - np.ones(len(bb_not_in_sample), dtype=int))\n",
    "    node_labels_dict = {}\n",
    "    for i in bb_in_sample_nodes:\n",
    "        node_labels_dict[i] = bb_labels[i-1]\n",
    "\n",
    "    # Calculate 2-D postions of BB centres (for graphing)\n",
    "    bb_pos_nodes = {}\n",
    "    for i in bb_in_sample:\n",
    "        bb_pos_ = expand_dims(bb_pos[i], 1) # homogenous coordinates\n",
    "        bb_pos_nodes_screen = world2screen_proj(bb_pos_, camera_pos, camera_rot, height_pixels, width_pixels)\n",
    "\n",
    "        x = np.ravel(bb_pos_nodes_screen[0])\n",
    "        x = x.astype(int)\n",
    "        x = x.item()\n",
    "        x = np.clip(x, 0, width_pixels)\n",
    "\n",
    "        y = np.ravel(bb_pos_nodes_screen[1])\n",
    "        y = y.astype(int)\n",
    "        y = y.item()\n",
    "        y = - y + height_pixels\n",
    "        y = np.clip(y, 0, height_pixels)\n",
    "\n",
    "        bb_pos_nodes[i] = (x, y)\n",
    "    \n",
    "    # Define graph\n",
    "    rows, cols = np.where(adjacency_matrix == 1)\n",
    "    rows = rows + 1\n",
    "    cols = cols + 1\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "\n",
    "    gr.add_nodes_from(bb_in_sample)\n",
    "    gr.add_edges_from(edges)\n",
    "\n",
    "    y_lim, x_lim = tonemap.shape[:-1]\n",
    "    extent = 0, x_lim, 0, y_lim\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(tonemap, extent=extent, interpolation='nearest')\n",
    "    nx.draw(gr, pos=bb_pos_nodes, node_size=50, with_labels=True, labels=node_labels_dict, font_size=10)\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_scene(scene_name, scene_dir):\n",
    "    detail_dir = os.path.join(scene_dir, \"_detail\")\n",
    "\n",
    "    bb_size_dir = os.path.join(detail_dir, \"mesh\", \"metadata_semantic_instance_bounding_box_object_aligned_2d_extents.hdf5\")\n",
    "    bb_pos_dir = os.path.join(detail_dir, \"mesh\", \"metadata_semantic_instance_bounding_box_object_aligned_2d_positions.hdf5\")\n",
    "    bb_rot_dir = os.path.join(detail_dir, \"mesh\", \"metadata_semantic_instance_bounding_box_object_aligned_2d_orientations.hdf5\")\n",
    "\n",
    "    mesh_objects_si_dir = os.path.join(\"evermotion_dataset\", \"scenes\", scene_name, \"_detail\", \"mesh\", \"mesh_objects_si.hdf5\")\n",
    "    mesh_objects_sii_dir = os.path.join(\"evermotion_dataset\", \"scenes\", scene_name, \"_detail\", \"mesh\", \"mesh_objects_sii.hdf5\")\n",
    "    metadata_objects_dir = os.path.join(\"evermotion_dataset\", \"scenes\", scene_name, \"_detail\", \"mesh\", \"metadata_objects.csv\")\n",
    "    a2m_dir = os.path.join(detail_dir, \"metadata_scene.csv\")\n",
    "\n",
    "    with h5py.File(bb_size_dir, \"r\") as f: bb_sizes = f['dataset'][:]\n",
    "    with h5py.File(bb_rot_dir, \"r\") as f: bb_rot = f['dataset'][:]\n",
    "    with h5py.File(bb_pos_dir, \"r\") as f: bb_pos = f['dataset'][:]\n",
    "\n",
    "    with h5py.File(mesh_objects_si_dir, \"r\") as f: mesh_objects_si = f['dataset'][:]\n",
    "    with h5py.File(mesh_objects_sii_dir, \"r\") as f: mesh_objects_sii = f['dataset'][:]\n",
    "    metadata_objects = genfromtxt(metadata_objects_dir, delimiter=None, dtype=str)\n",
    "\n",
    "    with open(a2m_dir, newline='') as csvfile:\n",
    "        metadata_scene = list(csv.reader(csvfile))\n",
    "        a2m = float(metadata_scene[1][1])\n",
    "    \n",
    "    return bb_sizes, bb_rot, bb_pos, mesh_objects_si, mesh_objects_sii, metadata_objects, a2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset_labels():\n",
    "    nyu_labels_dir = os.path.join(\"code\", \"cpp\", \"tools\", \"scene_annotation_tool\", \"semantic_label_descs.csv\")\n",
    "    nyu_labels = genfromtxt(nyu_labels_dir, delimiter=',', dtype=None, encoding=None, autostrip=True)\n",
    "\n",
    "    scene_labels_dir = os.path.join(\"evermotion_dataset\", \"analysis\", \"metadata_camera_trajectories.csv\")\n",
    "    scene_labels = genfromtxt(scene_labels_dir, delimiter=',', dtype=None, encoding=None, autostrip=True)[1:,[0,7,8]]\n",
    "    return nyu_labels, scene_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_camera(scene_dir, camera_name):\n",
    "    detail_dir = os.path.join(scene_dir, \"_detail\")\n",
    "    camera_pos_dir = os.path.join(detail_dir, camera_name, \"camera_keyframe_positions.hdf5\")\n",
    "    camera_rot_dir = os.path.join(detail_dir, camera_name, \"camera_keyframe_orientations.hdf5\")\n",
    "    with h5py.File(camera_pos_dir, \"r\") as f: camera_pos_all = f['dataset'][:]\n",
    "    with h5py.File(camera_rot_dir, \"r\") as f: camera_rot_all = f['dataset'][:]\n",
    "    return camera_pos_all, camera_rot_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_frame(tonemap_dir, segmentation_dir):\n",
    "    tonemap = imread(tonemap_dir)\n",
    "    with h5py.File(segmentation_dir, \"r\") as f: segmentation = f['dataset'][:]\n",
    "    return tonemap, segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 19.81it/s]\n"
     ]
    }
   ],
   "source": [
    "############ ARGS #############\n",
    "data_list = []\n",
    "download_dir = r\".\\contrib\\99991\\downloads\"\n",
    "scene_name = r\"ai_001_005\"\n",
    "camera_name = r\"cam_00\"\n",
    "###############################\n",
    "\n",
    "\n",
    "####################### LOOP THRU SCENES #############################\n",
    "\n",
    "scene_dir = os.path.join(download_dir, scene_name)\n",
    "images_dir = os.path.join(scene_dir, \"images\") # frame\n",
    "detail_dir = os.path.join(scene_dir, \"_detail\")\n",
    "n_cams = len(glob.glob(detail_dir + \"/*/\"))-1\n",
    "\n",
    "############### LOOP THRU CAMERAS #################\n",
    "\n",
    "preview_files_dir = os.path.join(images_dir, \"scene_\" + camera_name + \"_final_preview\") # frame\n",
    "geometry_files_dir = os.path.join(images_dir, \"scene_\" + camera_name + \"_geometry_hdf5\") # frame\n",
    "\n",
    "# Import dataset-, scene- and camera-specific files\n",
    "nyu_labels, scene_labels = import_dataset_labels()\n",
    "bb_sizes, bb_rot, bb_pos, mesh_objects_si, mesh_objects_sii, metadata_objects, a2m = import_scene(scene_name, scene_dir)\n",
    "camera_pos_all, camera_rot_all = import_camera(scene_dir, camera_name)\n",
    "\n",
    "#### Assign a label to each BB (scene-specific assignment)\n",
    "n_bb = bb_pos.shape[0] - 1\n",
    "bb_labels, bb_error = assign_labels(mesh_objects_sii, mesh_objects_si, metadata_objects, nyu_labels, bb_pos)\n",
    "\n",
    "# Frame-specific files\n",
    "tonemap_files_dir = os.path.join(images_dir, \"scene_\" + camera_name + \"_final_preview\", \"frame.*.tonemap.jpg\")\n",
    "segmentation_files_dir = os.path.join(images_dir, \"scene_\" + camera_name + \"_geometry_hdf5\", \"frame.*.semantic_instance.hdf5\")\n",
    "\n",
    "filenames_tonemap = [ os.path.basename(f) for f in sort(glob.glob(tonemap_files_dir)) ]\n",
    "filenames_segmentation = [ os.path.basename(f) for f in sort(glob.glob(segmentation_files_dir)) ]\n",
    "# n_frames = len(filenames_tonemap)\n",
    "n_frames = 3\n",
    "print(n_frames)\n",
    "\n",
    "# Calculate Euclidian distance between nodes and compare to threshold value\n",
    "# Only need to calculate the distance mask once for every scene\n",
    "threshold = 1.5\n",
    "distance_mask = calculate_distance(threshold, a2m, bb_pos, bb_error)\n",
    "\n",
    "# Obtain label graph (used for all scenes)\n",
    "scene_names = [y[:-7] for y in scene_labels[:,0]]\n",
    "scene_labels_c = np.c_[scene_names, scene_labels[:,1:]]\n",
    "scenes = np.unique(scene_labels[:,1])\n",
    "scene = None\n",
    "remove = []\n",
    "\n",
    "for i, row in enumerate(scene_labels_c):\n",
    "    if row[0] == scene:\n",
    "        remove.append(i)\n",
    "    else:\n",
    "        scene = row[0]\n",
    "\n",
    "remove = np.array(remove)\n",
    "scene_labels_c = np.delete(scene_labels_c, remove, axis=0)\n",
    "\n",
    "scene_ids = np.zeros_like(scene_labels_c[:,0], dtype=int)\n",
    "# print(scene_ids)\n",
    "for i, s in enumerate(scenes):\n",
    "    s_id = np.where(scene_labels_c[:,1] == s)\n",
    "    scene_ids[s_id] = i\n",
    "\n",
    "# scene_labels_c = np.concatenate((scene_labels_c, scene_ids[:, np.newaxis]), axis=1, dtype=object)\n",
    "scene_labels_c = np.concatenate((scene_labels_c, scene_ids[:, np.newaxis]), axis=1)\n",
    "y = torch.tensor(scene_labels_c[:,3].astype(int))\n",
    "\n",
    "# Iterate through frames (given scene and camera):\n",
    "for tonemap_file, segmentation_file, frame_id in tqdm(zip(filenames_tonemap[:n_frames], filenames_segmentation[:n_frames], arange(n_frames)), total=n_frames):\n",
    "    counter = 0\n",
    "    tonemap_dir = os.path.join(preview_files_dir, tonemap_file)\n",
    "    segmentation_dir =  os.path.join(geometry_files_dir, segmentation_file)\n",
    "\n",
    "    # Load tonemap and segmentation for current frame\n",
    "    tonemap, segmentation = import_frame(tonemap_dir, segmentation_dir)\n",
    "    # print(frame_id, \": loaded\", tonemap_file, \"and\", segmentation_file)\n",
    "\n",
    "    # Select BB that are present in current frame\n",
    "    bb_in_sample = unique(segmentation)\n",
    "    if bb_in_sample[0] == -1:\n",
    "        bb_in_sample = bb_in_sample[1:] # discard -1 label (pixels in segmentation map with unidentified BB)\n",
    "    n_bb_in_sample = bb_in_sample.shape[0]\n",
    "\n",
    "    # Construct adjacency matrix\n",
    "    adjacency_matrix = construct_adjacency_matrix(n_bb, bb_in_sample, distance_mask)\n",
    "\n",
    "    # Transform adjacency matrix to adjacency list in COO format\n",
    "    row, col = np.where(adjacency_matrix)\n",
    "    edge_index_np = np.array(list(zip(row, col)))\n",
    "\n",
    "    nodes_present = unique(edge_index_np) # refers to BB number, indexing starts at 0\n",
    "    new_idx = []\n",
    "    for node0, node1 in edge_index_np:\n",
    "        new_node0 = np.where(node0 == nodes_present)[0][0]\n",
    "        new_node1 = np.where(node1 == nodes_present)[0][0]\n",
    "        new_idx.append((new_node0, new_node1))\n",
    "    edge_index = torch.tensor(np.array(new_idx)).t()\n",
    "    \n",
    "    # Transform bb_labels to node features (tensor matrix with shape [num_nodes, num_node_features])\n",
    "    bb_labels_in_sample = np.array([bb_labels[i-1] for i in bb_in_sample]) # indexing starts at 0\n",
    "    x = torch.tensor(np.array(bb_labels_in_sample)) # indexing starts at 0\n",
    "\n",
    "    # Get relevant graph label\n",
    "    y_scene = y[np.where(scene_name == scene_labels_c[:,0])]\n",
    "\n",
    "    # Construct Data object\n",
    "    data = Data(edge_index=edge_index, x=x, y=y_scene)\n",
    "    # print(data)\n",
    "    data_list.append(data)\n",
    "    # if counter == 0:\n",
    "    #     hf = h5py.File('data.h5', 'a')\n",
    "    #     hf.create_dataset('dataset', data=data, compression=\"gzip\", chunks=True, maxshape=(None,))\n",
    "\n",
    "    # counter += 1    \n",
    "    \n",
    "    # ############ PLOTTING ############\n",
    "    # # Plot labelled BB as graph on top of tonemap\n",
    "    # # First, calculate frame-specific variables (image size and camera placement for current frame)\n",
    "    # height_pixels = tonemap.shape[0] \n",
    "    # width_pixels  = tonemap.shape[1]\n",
    "    # camera_pos = camera_pos_all[frame_id]\n",
    "    # camera_rot = camera_rot_all[frame_id]\n",
    "    # # Then, plot\n",
    "    # plot_scene(n_bb, bb_pos, bb_in_sample, camera_pos, camera_rot, height_pixels, width_pixels, adjacency_matrix, bb_labels, tonemap)\n",
    "    # if n_frames > 1:\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis = to_networkx(data)\n",
    "# plt.figure(1,figsize=(8,8)) \n",
    "# nx.draw(vis, cmap=plt.get_cmap('Set3'), node_size=70,linewidths=6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'Office (music studio)' 'Office (music studio)'\n",
      " 'Office (music studio)' 'Office (music studio)' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' 'Hallway (outdoor; weird)'\n",
      " 'Bathroom (weird)' '' 'Retail space (weird)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Art gallery', 'Bathroom', 'Bedroom', 'Courtyard', 'Dining room',\n",
       "       'Hall', 'Hallway', 'Hotel lobby', 'Kitchen', 'Lecture theater',\n",
       "       'Library', 'Living room',\n",
       "       'OUTSIDE VIEWING AREA (BAD INITIALIZATION)',\n",
       "       'OUTSIDE VIEWING AREA (BAD TRAJECTORY)', 'Office',\n",
       "       'Office (building foyer)', 'Office (conference room)',\n",
       "       'Office (home)', 'Office (waiting area)', 'Other', 'Restaurant',\n",
       "       'Retail space', 'Staircase', 'Transit station'], dtype='<U50')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: delete scenes with added comment (usually weird or unusual scenes)\n",
    "print(scene_labels[:30,2]) # preview first 30 items\n",
    "\n",
    "# TODO: assign graph label based on one of these (number them)\n",
    "# TODO: delete scenes with OUTSIDE...\n",
    "scenes = np.unique(scene_labels[:,1])\n",
    "scenes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
